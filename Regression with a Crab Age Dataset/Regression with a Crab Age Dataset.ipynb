{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T16:13:44.158557Z",
     "iopub.status.busy": "2023-06-13T16:13:44.157962Z",
     "iopub.status.idle": "2023-06-13T16:13:45.216711Z",
     "shell.execute_reply": "2023-06-13T16:13:45.215461Z",
     "shell.execute_reply.started": "2023-06-13T16:13:44.158507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "class FeatureCreator():\n",
    "    def __init__(self, add_attributes=True):\n",
    "        \n",
    "        self.add_attributes = add_attributes\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform_337(self, X):\n",
    "        \n",
    "        if self.add_attributes:\n",
    "            X_copy = X.copy()\n",
    "            \n",
    "            # X_copy['Shell Weight']=np.where(X_copy['Shell Weight']>X_copy['Weight'],X_copy['Weight'],X_copy['Shell Weight'])\n",
    "            # X_copy['Viscera Weight']=np.where(X_copy['Viscera Weight']>X_copy['Weight'],X_copy['Weight'],X_copy['Viscera Weight'])\n",
    "            # X_copy['Shucked Weight']=np.where(X_copy['Shucked Weight']>X_copy['Weight'],X_copy['Weight'],X_copy['Shucked Weight'])\n",
    "#             for i in range(len(X_copy)):\n",
    "#                 #weight\n",
    "#                 if X_copy.iloc[i,'Weight'] - X_copy.iloc[i,'Shell Weight'] <  X_copy.iloc[i,'Viscera Weight']*0.7:\n",
    "#                     X_copy.iloc[i,'Weight'] = X_copy.iloc[i,'Shell Weight'] + X_copy.iloc[i,'Shucked Weight']\n",
    "                \n",
    "#                 \n",
    "#                 if X_copy.iloc[i,'Weight'] < X_copy.iloc[i,'Shucked Weight']*0.5:\n",
    "#                     X_copy.iloc[i,'Shucked Weight'] = X_copy.iloc[i,'Weight'] - X_copy.iloc[i,'Shell Weight']\n",
    "\n",
    "            # weight\n",
    "#             mask1 = (X_copy['Weight'] - X_copy['Shell Weight']) <  X_copy['Viscera Weight']*0.7\n",
    "#             X_copy.loc[mask1, 'Weight'] = X_copy.loc[mask1, 'Shell Weight'] + X_copy.loc[mask1, 'Shucked Weight']\n",
    "\n",
    "#             \n",
    "#             mask2 = X_copy['Weight'] < X_copy['Shucked Weight']*0.5\n",
    "#             X_copy.loc[mask2, 'Shucked Weight'] = X_copy.loc[mask2, 'Weight'] - X_copy.loc[mask2, 'Shell Weight']\n",
    "            \n",
    "            #weight \n",
    "            #encoding_total\n",
    "            X_copy['total'] = np.log(np.round(X_copy['Weight']+\n",
    "                                           X_copy['Shucked Weight'] + X_copy['Viscera Weight'] + X_copy['Shell Weight'],5))\n",
    "            X_copy['encoding_total'] = X_copy['total'].map(X_copy['total'].value_counts().to_dict())\n",
    "            X_copy['encoding_total'] = np.log(X_copy['total']/X_copy['encoding_total']) / np.log(10)\n",
    "            \n",
    "                \n",
    "            X_copy[\"volume\"] = X_copy[\"Height\"] * X_copy[\"Diameter\"] * X_copy[\"Length\"]\n",
    "            #\n",
    "            X_copy[\"Surface Area\"] = 2 * (X_copy[\"Length\"] * X_copy[\"Diameter\"] + X_copy[\"Length\"] * X_copy[\"Height\"] + X_copy[\"Diameter\"] * X_copy[\"Height\"])\n",
    "            \n",
    "            X_copy[\"Density\"] = X_copy[\"Weight\"] / X_copy[\"volume\"]\n",
    "            X_copy[\"Shell Density\"] = X_copy[\"Shell Weight\"] / X_copy[\"volume\"]\n",
    "            \n",
    "            X_copy[\"dim1\"] = X_copy[\"Height\"] * X_copy[\"Diameter\"] \n",
    "            X_copy[\"dim2\"] = X_copy[\"Height\"] * X_copy[\"Length\"] \n",
    "            X_copy[\"dim3\"] = X_copy[\"Diameter\"] * X_copy[\"Length\"]\n",
    "            X_copy[\"total_weight\"] = X_copy[\"Shell Weight\"] + X_copy[\"Viscera Weight\"] + X_copy[\"Shucked Weight\"]\n",
    "            X_copy[\"weight_volume_ratio\"] = X_copy[\"Weight\"] / (X_copy[\"Diameter\"] + 1e-8 )\n",
    "            X_copy['Weight_to_Shucked_Weight'] = X_copy['Weight'] / X_copy['Shucked Weight']\n",
    "            X_copy[\"shell_to_total_weight\"] = X_copy[\"Shell Weight\"] / X_copy[\"Weight\"]\n",
    "            X_copy[\"viscera_to_total_weight\"] = X_copy[\"Viscera Weight\"] / X_copy[\"Weight\"]\n",
    "            X_copy[\"shucked_to_total_weight\"] = X_copy[\"Shucked Weight\"] / X_copy[\"Weight\"]\n",
    "            \n",
    "            X_copy['Meat Yield'] = X_copy['Shucked Weight'] / (X_copy['Weight'] + X_copy['Shell Weight'])\n",
    "            X_copy['Shell-to-Body Ratio'] = X_copy['Shell Weight'] / (X_copy['Weight'] + X_copy['Shell Weight'])\n",
    "            X_copy['Pseudo BMI']=X_copy['Weight']/(X_copy['Height']**2)\n",
    "            \n",
    "            #Ratio\n",
    "            X_copy['Shucked Weight/total_weight'] = X_copy['Shucked Weight'] / X_copy['total_weight']\n",
    "            X_copy['Viscera Weight/total_weight'] = X_copy['Viscera Weight'] / X_copy['total_weight']\n",
    "            X_copy['Shell Weight/total_weight'] = X_copy['Shell Weight'] / X_copy['total_weight']\n",
    "            \n",
    "            #转换\n",
    "            \n",
    "            X_copy['total_weight'] = np.log1p(X_copy['total_weight'])\n",
    "            X_copy['Weight'] = np.log1p(X_copy['Weight'])\n",
    "            X_copy['Shell Weight'] = np.log1p(X_copy['Shell Weight'])\n",
    "            X_copy['Viscera Weight'] = np.log1p(X_copy['Viscera Weight'])\n",
    "            X_copy['Shucked Weight'] = np.log1p(X_copy['Shucked Weight'])\n",
    "            X_copy['Length'] = np.log1p(X_copy['Length'])\n",
    "            # X_copy['Diameter'] = np.log1p(X_copy['Diameter'])\n",
    "            # X_copy['Height'] = np.log1p(X_copy['Height'])\n",
    "            # X_copy['Height'] = round(X_copy['Height'],2)\n",
    "            # X_copy['Diameter'] = round(X_copy['Diameter'],2)\n",
    "            \n",
    "            X_copy['Body Condition Index'] = np.sqrt(X_copy['Length'] * X_copy['Weight'] * X_copy['Shucked Weight'])\n",
    "            \n",
    "            X_copy[\"Weight_wo_Viscera\"] = X_copy['Shucked Weight'] - X_copy['Viscera Weight']\n",
    "            return X_copy\n",
    "        else:\n",
    "            return X_copy\n",
    "        \n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "original=pd.read_csv(\"data/CrabAgePrediction.csv\")\n",
    "original[\"original\"]=1\n",
    "train[\"original\"]=0\n",
    "test[\"original\"]=0\n",
    "train.drop(columns=[\"id\"],inplace=True)\n",
    "test.drop(columns=[\"id\"],inplace=True)\n",
    "train=pd.concat([train,original],axis=0)\n",
    "train.reset_index(inplace=True,drop=True)\n",
    "fe = FeatureCreator(add_attributes = True)\n",
    "original_feature = list(train.drop(columns = ['Age']).columns.values)\n",
    "train = fe.transform_337(train)\n",
    "test = fe.transform_337(test)\n",
    "\n",
    "feature = ['dim1','Meat Yield']\n",
    "train = train[list(set(feature + original_feature + ['Age']))]\n",
    "test = test[list(set(feature + original_feature))]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def encoder(df):\n",
    "    drop_col = []\n",
    "    categorical_features = ['Sex']\n",
    "    df = df.copy().drop(columns= drop_col).reset_index(drop = True)\n",
    "\n",
    "    for column in categorical_features:\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # encoded_train[column] = label_encoder.fit_transform(encoded_train[column])\n",
    "        # encoded_test[column] = label_encoder.transform(encoded_test[column])\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "        mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "        #print(f\"{column} for {mapping}\")\n",
    "        print(f\"{column}\")\n",
    "    mapping = dict(zip(label_encoder.classes_,range(len(label_encoder.classes_))))\n",
    "    return df,mapping\n",
    "\n",
    "train,mapping = encoder(train)\n",
    "test['Sex'] = test['Sex'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T11:49:34.595627Z",
     "iopub.status.busy": "2023-06-13T11:49:34.595282Z",
     "iopub.status.idle": "2023-06-13T11:49:34.604451Z",
     "shell.execute_reply": "2023-06-13T11:49:34.603311Z",
     "shell.execute_reply.started": "2023-06-13T11:49:34.595602Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_targets = np.unique(train.Age)\n",
    "def mattop_post_process(preds):\n",
    "     return np.array([min(unique_targets, key = lambda x: abs(x - pred)) for pred in preds])\n",
    "    \n",
    "def post2(preds):\n",
    "    result = []\n",
    "    for i in preds:\n",
    "        result.append(int((i * 2 + 1) // 2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T11:49:36.132681Z",
     "iopub.status.busy": "2023-06-13T11:49:36.131974Z",
     "iopub.status.idle": "2023-06-13T11:49:38.205231Z",
     "shell.execute_reply": "2023-06-13T11:49:38.204442Z",
     "shell.execute_reply.started": "2023-06-13T11:49:36.132636Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,precision_score,recall_score,accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "import lightgbm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import plot_metric\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "from functools import partial\n",
    "class OptunaWeights:\n",
    "    def __init__(self, random_state, n_trials=100):\n",
    "        self.study = None\n",
    "        self.weights = None\n",
    "        self.random_state = random_state\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def _objective(self, trial, y_true, y_preds):\n",
    "        # Define the weights for the predictions from each model\n",
    "        weights = [trial.suggest_float(f\"weight{n}\", 1e-15, 1) for n in range(len(y_preds))]\n",
    "\n",
    "        # Calculate the weighted prediction\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=weights)\n",
    "\n",
    "        # Calculate the score for the weighted prediction\n",
    "        y_true = y_true.to_list()\n",
    "        score = 0\n",
    "        for i in range(len(y_true)):\n",
    "            # if y_true[i]>=18:\n",
    "            #     score += np.abs(y_true[i]-weighted_pred[i])*(1+np.abs((y_true[i]-weighted_pred[i])/(30-y_true[i])))\n",
    "            # else:\n",
    "            #     score += np.abs(y_true[i]-weighted_pred[i])\n",
    "            score += np.abs(y_true[i]-weighted_pred[i])*(1+np.abs((y_true[i]-weighted_pred[i])/(30-y_true[i])))\n",
    "            \n",
    "            # score += np.abs(y_true[i]-weighted_pred[i])*(1+(y_true[i])/np.abs((y_true[i]-weighted_pred[i])*0.1))\n",
    "        score /= len(y_true)\n",
    "        # score = np.abs(y_true-weighted_pred) * (1+np.abs((y_true-weighted_pred))/(29-y_true))\n",
    "        # score = mean_absolute_error(y_true, weighted_pred)\n",
    "        return score\n",
    "\n",
    "    def fit(self, y_true, y_preds):\n",
    "        optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n",
    "        pruner = optuna.pruners.HyperbandPruner()\n",
    "        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='minimize')\n",
    "        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n",
    "        self.study.optimize(objective_partial, n_trials=self.n_trials)\n",
    "        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n",
    "\n",
    "    def predict(self, y_preds):\n",
    "        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=self.weights)\n",
    "        return weighted_pred\n",
    "\n",
    "    def fit_predict(self, y_true, y_preds):\n",
    "        self.fit(y_true, y_preds)\n",
    "        return self.predict(y_preds)\n",
    "    \n",
    "    def weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T11:49:48.957925Z",
     "iopub.status.busy": "2023-06-13T11:49:48.957575Z",
     "iopub.status.idle": "2023-06-13T12:28:03.187824Z",
     "shell.execute_reply": "2023-06-13T12:28:03.187147Z",
     "shell.execute_reply.started": "2023-06-13T11:49:48.957902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------->Fold 1<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3260399783900594\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3282009724473258\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3296866558616964\n",
      "Ensemble MAE: 1.3268503511615344\n",
      "Weight is [0.5397142305629359, 0.30959293423439915, 0.0038380484644549495]\n",
      "---------->Fold 2<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3411510985307993\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3385901064833536\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.346677449791077\n",
      "Ensemble MAE: 1.3342768567192345\n",
      "Weight is [0.7850524037270756, 0.2772864220200569, 0.2118282512833785]\n",
      "---------->Fold 3<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3307702684473224\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3337380277890194\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.336570888978821\n",
      "Ensemble MAE: 1.3309051665992175\n",
      "Weight is [0.020436139839504392, 0.9315771407895964, 0.1791539827286753]\n",
      "---------->Fold 4<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3310792534487421\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.333378414931025\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3429807952393833\n",
      "Ensemble MAE: 1.3327021909656478\n",
      "Weight is [0.7949527536168494, 3.76418030168552e-12, 0.05704494327267275]\n",
      "---------->Fold 5<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3318385650224216\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.331702676994157\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3348281016442451\n",
      "Ensemble MAE: 1.3281695882592743\n",
      "Weight is [0.2611742774409896, 0.8236240882479966, 0.05938879834136627]\n",
      "---------->Fold 6<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3433098591549295\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.347643553629469\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3479144095341278\n",
      "Ensemble MAE: 1.3430390032502708\n",
      "Weight is [0.28792505687616565, 0.7295890495262696, 0.06399169725812683]\n",
      "---------->Fold 7<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3220590216951893\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.323271796253874\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3323002290796389\n",
      "Ensemble MAE: 1.3217895162377038\n",
      "Weight is [0.4628305016384763, 0.6313739664956568, 1.631113916133186e-12]\n",
      "---------->Fold 8<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3428417653390743\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.336383207750269\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3532023681377825\n",
      "Ensemble MAE: 1.336383207750269\n",
      "Weight is [0.46409764608865933, 0.10402201646975621, 0.04186830017677785]\n",
      "---------->Fold 9<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3393628509719222\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3346382289416847\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3502969762419006\n",
      "Ensemble MAE: 1.3346382289416847\n",
      "Weight is [0.647692803601107, 0.0981355262101648, 0.011142984025382307]\n",
      "---------->Fold 10<----------\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            CatBoost                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3353107725495483\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] early_stopping_round is set=200, early_stopping_rounds=200 will be ignored. Current value: early_stopping_round=200\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            LightGBM                |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3374679789672375\n",
      "|------------------------------------|\n",
      "|                                    |\n",
      "|            XGBoost                 |\n",
      "|                                    |\n",
      "|------------------------------------|\n",
      " \n",
      "------------- Train -----------------\n",
      "MAE: 1.3400296615882432\n",
      "Ensemble MAE: 1.333558042335176\n",
      "Weight is [0.05103379303297531, 0.4180456032316038, 0.041472159291573094]\n",
      "Average ctb is : 1.3343763433550007 ; lgb is : 1.3345014964187416 ; xgb is : 1.3414487536096915\n",
      "final Ensemble MAE: 1.3322312152220013\n",
      "CPU times: total: 43min 9s\n",
      "Wall time: 29min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def cv(train, test, target,kfold = None):\n",
    "    n_reapts = 1\n",
    "    random_state = 42\n",
    "    n_estimators = 99999\n",
    "    n_trials = 3500\n",
    "    early_stopping_rounds = 2000\n",
    "    verbose = False\n",
    "    device = 'cpu'\n",
    "    ensemble_score = []\n",
    "    fold_scores = []\n",
    "    weights = []\n",
    "    oof_each_predss = []\n",
    "    test_each_predss = []\n",
    "    ensemble_test = np.zeros(len(test))\n",
    "    oof_predss = np.zeros(len(train[train['original']==0]))\n",
    "    # Fix seed\n",
    "    random.seed(random_state)\n",
    "    random_state_list = random.sample(range(9999), n_reapts)\n",
    "    \n",
    "    test_preds = np.zeros((len(test)))\n",
    "    cv = 0\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=42)\n",
    "    train_targets = train[target]\n",
    "    train = train.drop(columns = [target])\n",
    "    xgb_mae = 0\n",
    "    lgb_mae = 0\n",
    "    ctb_mae = 0\n",
    "    final_result = []\n",
    "    Ensemble_MAE = 0\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train, train_targets)):\n",
    "        print(\"-\"*10 + \">\" + f\"Fold {fold+1}\" + \"<\" + \"-\"*10)\n",
    "        \n",
    "        X_train, X_valid = train.iloc[train_idx], train.iloc[valid_idx]\n",
    "        y_train, y_valid = train_targets.iloc[train_idx], train_targets.iloc[valid_idx]\n",
    "        \n",
    "        \n",
    "        ctb =CatBoostRegressor(n_estimators=10000, \n",
    "                            early_stopping_rounds=200,\n",
    "                            **{'depth': 8, 'l2_leaf_reg': 0.5, 'max_bin': 150,'subsample':0.5,'colsample_bylevel':0.5,'min_data_in_leaf':256,\n",
    "                               'max_leaves':255,'l2_leaf_reg':0.1,\n",
    "                               'one_hot_max_size': 100,'grow_policy': 'Lossguide',#'bootstrap_type': 'Bayesian'\n",
    "                                'learning_rate': 0.01,\"thread_count\":-1,'loss_function':'MAE'})#'subsample': 0.55213213\n",
    "        \n",
    "        ctb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "        \n",
    "        ctb_preds = ctb.predict(X_valid[X_valid['original']==0])\n",
    "        ctb_test_preds = ctb.predict(test)\n",
    "        \n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            CatBoost                |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"MAE: {mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(ctb_preds))}\")\n",
    "        print(\" \")\n",
    "        ctb_mae += mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(ctb_preds))\n",
    "        \n",
    "    \n",
    "        \n",
    "        lgb = LGBMRegressor(n_estimators=10000, \n",
    "                            early_stopping_rounds=200,\n",
    "                            **{'max_depth': 7, \n",
    "                                'subsample': 0.5, \n",
    "                                'colsample_bytree': 0.5, \n",
    "                                \"num_leaves\": 255,\n",
    "                                \"min_data_in_leaf\": 200,\n",
    "                                'learning_rate': 0.019000000000000003,\n",
    "                                'objective':'mae','n_jobs':-1,'metric': 'mae',\"reg_alpha\": 0.2, \"reg_lambda\": 0.2})\n",
    "        \n",
    "        lgb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0,eval_metric='mae')\n",
    "        # plot_metric(lgb,'mae')\n",
    "        lgb_preds = lgb.predict(X_valid[X_valid['original']==0])\n",
    "        lgb_test_preds = lgb.predict(test)\n",
    "\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            LightGBM                |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"MAE: {mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(lgb_preds))}\")\n",
    "        lgb_mae += mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(lgb_preds))\n",
    "        \n",
    "        \n",
    "        xgb = XGBRegressor(n_estimators=10000, \n",
    "                            early_stopping_rounds=200,\n",
    "                            **{'max_depth': 9, 'subsample': 0.6, 'colsample_bytree': 0.6, \n",
    "                            'learning_rate': 0.01,'objective':'reg:squarederror','n_jobs':-1,'max_bin': 249,\n",
    "                               'booster': 'gbtree','grow_policy':'depthwise','gamma':0.5,'reg_alpha':0.8631578947368421,'reg_lambda':0.1,'eval_metric':'mae',\n",
    "                               'max_leaves':512,'tree_method': 'hist'})\n",
    "        \n",
    "        xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "        \n",
    "        xgb_preds = xgb.predict(X_valid[X_valid['original']==0])\n",
    "        xgb_test_preds = xgb.predict(test)\n",
    "        \n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            XGBoost                 |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"MAE: {mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(xgb_preds))}\")\n",
    "        xgb_mae += mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(xgb_preds))\n",
    "\n",
    "    \n",
    "        meta_train = [lgb_preds, ctb_preds, xgb_preds]\n",
    "        meta_test = [lgb_test_preds, ctb_test_preds, xgb_test_preds]\n",
    "        final_result.append(meta_test)\n",
    "        # Use Optuna to find the best ensemble weights\n",
    "        optweights = OptunaWeights(random_state=random_state, n_trials=n_trials)\n",
    "        y_val_pred = optweights.fit_predict(y_valid[X_valid['original']==0], meta_train)\n",
    "        print(f\"Ensemble MAE: {mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(y_val_pred))}\")\n",
    "        Ensemble_MAE += mean_absolute_error(y_valid[X_valid['original']==0], mattop_post_process(y_val_pred))/kfold\n",
    "        print(f\"Weight is {optweights.weights}\")\n",
    "        \n",
    "        weights.append(optweights.weights)\n",
    "\n",
    "        # Predict to X_test by the best ensemble weights\n",
    "        ensemble_test += optweights.predict(meta_test) / (kfold * len(random_state_list))#平均每折的结果\n",
    "        oof_predss[X_valid[X_valid['original']==0].index] = optweights.predict(meta_train)\n",
    "    print(f\"Average ctb is : {ctb_mae/kfold} ; lgb is : {lgb_mae/kfold} ; xgb is : {xgb_mae/kfold}\")\n",
    "    print(f\"final Ensemble MAE: {Ensemble_MAE}\")\n",
    "    return oof_predss,final_result,ensemble_test\n",
    "meta_train,meta_test,test_pred = cv(train = train, test = test, target = 'Age',kfold=10)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T12:28:52.498497Z",
     "iopub.status.busy": "2023-06-13T12:28:52.498125Z",
     "iopub.status.idle": "2023-06-13T12:28:52.515224Z",
     "shell.execute_reply": "2023-06-13T12:28:52.513914Z",
     "shell.execute_reply.started": "2023-06-13T12:28:52.49847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 1.3322304897975719\n",
      "after 1.3322034813844512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4528\\3592410519.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  copy_train['pred'] = np.round(meta_train)\n"
     ]
    }
   ],
   "source": [
    "copy_train = train[train['original']==0]\n",
    "copy_train['pred'] = np.round(meta_train)\n",
    "print(f\"before {mean_absolute_error(copy_train['Age'],copy_train['pred'])}\")\n",
    "copy_train.loc[(copy_train['pred']>18) & (copy_train['pred']<=19),'pred'] = np.round(copy_train.loc[(copy_train['pred']>18)& (copy_train['pred']<=19),'pred']-2)\n",
    "copy_train.loc[(copy_train['pred']>19),'pred'] = np.round(copy_train.loc[(copy_train['pred']>19),'pred']-1)\n",
    "print(f\"after {mean_absolute_error(copy_train['Age'],copy_train['pred'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T12:29:09.344693Z",
     "iopub.status.busy": "2023-06-13T12:29:09.344353Z",
     "iopub.status.idle": "2023-06-13T12:29:09.876461Z",
     "shell.execute_reply": "2023-06-13T12:29:09.875542Z",
     "shell.execute_reply.started": "2023-06-13T12:29:09.34467Z"
    }
   },
   "outputs": [],
   "source": [
    "pre = pd.DataFrame()\n",
    "pre['id'] = pd.read_csv('data/test.csv')['id']\n",
    "pre['Age'] = mattop_post_process(test_pred)   #      np.median(np.mean(meta_test,axis=0),axis=0)\n",
    "pre.loc[(pre['Age']>18) & (pre['Age']<=19),'Age'] = np.round(pre.loc[(pre['Age']>18)& (pre['Age']<=19),'Age']-2)\n",
    "pre.loc[(pre['Age']>19),'Age'] = np.round(pre.loc[(pre['Age']>19),'Age']-1)\n",
    "pre.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
